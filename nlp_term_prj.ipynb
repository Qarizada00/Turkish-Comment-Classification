{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this study, The goal was to measure different classification algorithms on given dataset named \"hepsiburada-product-comments.cvs\". Therefore, I've decided to perform it by measuring on 4 different classifiers. \n",
    "<br >Firstly, I developed a classifier with sequantial layers which The model takes in sequences of integers, converts them to dense vectors, and passes them through three GRU layers. The final output is a binary classification prediction. In pre-trained models, It has been decided to use the logistic regression and Naive Bayes classifiers. Finally, as Pre-trained transformer model the BERT has been used. The informations regarding to code parts and tasks are commented above the codes. The results of all models are mention in below table.\n",
    "<br><br>\n",
    "| Our developed | Logistic Regression | Naive Bayes | Bert |\n",
    "|----------|----------|----------|----------|\n",
    "| 0.98 | 0.98 | 0.97 | 0.93 |\n",
    "\n",
    "<br><br>\n",
    "With all respects.<br>\n",
    "Author and researcher: Nasibulah Qarizada - 1900004691<br>\n",
    "Istanbul Kultur University<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, LSTM, SimpleRNN, Embedding\n",
    "from keras.layers import Activation, Bidirectional, GlobalMaxPool1D, GlobalMaxPool2D, Dropout\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "import os \n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uno Flip</td>\n",
       "      <td>Orijinal ürün, hızlı kargo! Oyunu henüz oynama...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uno Flip</td>\n",
       "      <td>Merhaba, \\nDaha önce yapmış olduğum yorumda ka...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Product                                         reviewText  overall  B1  \\\n",
       "0  Uno Flip  Orijinal ürün, hızlı kargo! Oyunu henüz oynama...        5   5   \n",
       "1  Uno Flip  Merhaba, \\nDaha önce yapmış olduğum yorumda ka...        5   3   \n",
       "\n",
       "   B2  \n",
       "0   6  \n",
       "1   1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Nasibullah Qarizada\\\\Desktop\\\\hepsiburada-product-comments.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Exploratory Analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:947031\n",
      "number of unique reviewTexts: 790258\n",
      "percentage of duplicates: 16.554157150082734%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'number of samples:{len(df.reviewText)}')\n",
    "print(f'number of unique reviewTexts: {df.reviewText.nunique()}')\n",
    "print(f'percentage of duplicates: {(len(df.reviewText) - df.reviewText.nunique()) / len(df.reviewText)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947031, 5)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product          0\n",
       "reviewText    5049\n",
       "overall          0\n",
       "B1               0\n",
       "B2               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['overall'].value_counts().plot(kind = 'bar')\n",
    "#dataset['Product'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Preprocessing</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as first step we start with dropping NAN values.\n",
    "df = df.dropna()\n",
    "#Drop column with no potantiality of use.\n",
    "df = df.drop('B1', axis=1)\n",
    "df = df.drop('B2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    825312\n",
       "0     60169\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#firtly, we drop all the rows with 3 value since the appear as nuetral values in this study.\n",
    "df.drop(df[df[\"overall\"] == 3].index, inplace = True)\n",
    "#we classify the values over 3 as 1, below 3 as 0.\n",
    "df[\"overall\"] = df[\"overall\"].replace(1, 0)\n",
    "df[\"overall\"] = df[\"overall\"].replace(2, 0)\n",
    "df[\"overall\"] = df[\"overall\"].replace(4, 1)\n",
    "df[\"overall\"] = df[\"overall\"].replace(5, 1)\n",
    "df[\"overall\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all puncuations\n",
    "def remove_punctuation(text):\n",
    "    no_punc = [words for words in text if words not in string.punctuation]\n",
    "    word_wo_punc = \"\".join(no_punc)\n",
    "    return word_wo_punc\n",
    "#remove numbers\n",
    "def remove_numeric(corpus):\n",
    "    output = \"\".join(words for words in corpus if not words.isdigit())\n",
    "    return output\n",
    "\n",
    "#the first 4 lines lower cases, removes the panctuations and replace the \\n and \\r values as empty spaces to prevent any misunderstandings with the model and last raw drop the numeric values.\n",
    "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: x.lower())\n",
    "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: remove_punctuation(x))\n",
    "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: x.replace(\"\\r\", \" \"))\n",
    "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: x.replace(\"\\n\", \" \"))\n",
    "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: remove_numeric(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Train Test Split</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"overall\"].values.tolist()\n",
    "data = df[\"reviewText\"].values.tolist()\n",
    "\n",
    "cutoff = int(len(data)*0.80)\n",
    "\n",
    "X_train, X_test = data[:cutoff], data[cutoff:]\n",
    "y_train, y_test = target[:cutoff], target[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code sets a maximum number of words, initializes a tokenizer object, and then fits the tokenizer on the input data to create a word index based on the frequency of words.\n",
    "num_words = 100000\n",
    "tokenizer = Tokenizer(num_words = num_words)\n",
    "tokenizer.fit_on_texts(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kısa sürede ulaştı kolayca taktım güzel ürün']\n",
      "[111, 182, 37, 781, 600, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "#converts text data in X_train and X_test into sequences of integers using the tokenizer object, \n",
    "#and prints the original text of the 10000th element of X_train and its corresponding integer sequence.\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "print([X_train[10000]])\n",
    "print(X_train_tokens[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 37,  4, ..., 10, 21, 14])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculates the number of tokens for each element in the combined X_train_tokens and X_test_tokens lists, and stores them in a NumPy array num_tokens.\n",
    "num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\n",
    "num_tokens = np.array(num_tokens)\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculates the maximum number of tokens allowed for each sequence by taking the mean of the number of tokens in the num_tokens array, adding two standard deviations, converting the result to an integer, and storing it in the max_tokens variable.\n",
    "max_tokens = np.mean(num_tokens) + (2*np.std(num_tokens))\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708384, 60)\n",
      "(177097, 60)\n"
     ]
    }
   ],
   "source": [
    "#padding on the sequences in X_train_tokens and X_test_tokens to ensure they are all of equal length (maxlen), then stores the resulting padded sequences in X_train_pad and X_test_pad.\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen = max_tokens) \n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen = max_tokens)\n",
    "\n",
    "print(X_train_pad.shape)\n",
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code defines a function that converts a sequence of tokens back into its corresponding text.\n",
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))\n",
    "\n",
    "def tokens_to_string(tokens):\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    text = \" \".join(words) \n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Training the model</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2768/2768 [==============================] - 369s 131ms/step - loss: 0.1168 - accuracy: 0.9633\n",
      "Epoch 2/5\n",
      "2768/2768 [==============================] - 434s 157ms/step - loss: 0.0614 - accuracy: 0.9793\n",
      "Epoch 3/5\n",
      "2768/2768 [==============================] - 430s 155ms/step - loss: 0.0408 - accuracy: 0.9870\n",
      "Epoch 4/5\n",
      "2768/2768 [==============================] - 418s 151ms/step - loss: 0.0275 - accuracy: 0.9916\n",
      "Epoch 5/5\n",
      "2768/2768 [==============================] - 432s 156ms/step - loss: 0.0195 - accuracy: 0.9943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b757df4820>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size = 50\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = num_words, output_dim = embedding_size, input_length = max_tokens, name = \"embedding_layer\"))\n",
    "model.add(GRU(units = 16, return_sequences = True))\n",
    "model.add(GRU(units = 8, return_sequences = True))\n",
    "model.add(GRU(units = 4))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "X_train_pad = np.array(X_train_pad)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "model.fit(X_train_pad, y_train, epochs = 5, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.966481626033783\n",
      "F1 Score: 0.9819859189123573\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76     13089\n",
      "           1       0.98      0.99      0.98    164008\n",
      "\n",
      "    accuracy                           0.97    177097\n",
      "   macro avg       0.89      0.85      0.87    177097\n",
      "weighted avg       0.97      0.97      0.97    177097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert test data to numpy array and pad the sequences\n",
    "X_test_pad = np.array(X_test_pad)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test_pad)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the scores\n",
    "print('Test Accuracy:', accuracy)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 Score:', f1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Pre-trained models</font> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9631727245520816\n",
      "F1 Score: 0.9802980962680571\n",
      "Confusion Matrix:\n",
      "[[  8319   4770]\n",
      " [  1752 162256]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72     13089\n",
      "           1       0.97      0.99      0.98    164008\n",
      "\n",
      "    accuracy                           0.96    177097\n",
      "   macro avg       0.90      0.81      0.85    177097\n",
      "weighted avg       0.96      0.96      0.96    177097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "cutoff = int(len(data)*0.80)\n",
    "X_train, X_test = data[:cutoff], data[cutoff:]\n",
    "y_train, y_test = target[:cutoff], target[cutoff:]\n",
    "\n",
    "# Convert text data into numerical vectors using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression(C=1, max_iter=1000)\n",
    "logreg.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions on test set and calculate metrics\n",
    "y_pred = logreg.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Print metrics and confusion matrix\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 Score:', f1)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Naive Bayes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9519472379543414\n",
      "F1 Score: 0.9746052019050574\n",
      "Confusion Matrix:\n",
      "[[  5288   7801]\n",
      " [   709 163299]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.40      0.55     13089\n",
      "           1       0.95      1.00      0.97    164008\n",
      "\n",
      "    accuracy                           0.95    177097\n",
      "   macro avg       0.92      0.70      0.76    177097\n",
      "weighted avg       0.95      0.95      0.94    177097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "cutoff = int(len(data)*0.80)\n",
    "X_train, X_test = data[:cutoff], data[cutoff:]\n",
    "y_train, y_test = target[:cutoff], target[cutoff:]\n",
    "\n",
    "# Convert text data into numerical vectors using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions on test set and calculate metrics\n",
    "y_pred = nb.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print metrics and confusion matrix\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 Score:', f1)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"20\">Pre-trained transformers model </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Bert (Bidirectional Encoder Representation from transformers)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function encodes a list of texts into a sequence of token IDs using a given tokenizer, with chunking and padding for efficient processing.\n",
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=23):    \n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    tokenizer.enable_padding(length=maxlen)\n",
    "    all_ids = []\n",
    "    \n",
    "    for i in range(0, len(texts), chunk_size):\n",
    "        text_chunk = texts[i:i+chunk_size]\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "    return np.array(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(vocabulary_size=30522, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=None, lowercase=True, wordpieces_prefix=##)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code loads the pre-trained BERT tokenizer and saves it locally, and then creates a fast tokenizer using the same vocabulary file.\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "save_path = 'bert_base_uncased'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "fast_tokenizer = BertWordPieceTokenizer('bert_base_uncased/vocab.txt', lowercase=True)\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885481, 23)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns a numpy array with the encoded sequences\n",
    "X = fast_encode(data, fast_tokenizer, maxlen=23)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['overall'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((637545, 23), (88549, 23), (637545,), (88549,), (159387, 23), (159387,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#begin splittin train test as 10/90 ratio.\n",
    "X_train_valid,X_test,y_train_valid,y_test=train_test_split(X,y,test_size=0.1,random_state=42)\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X_train_valid,y_train_valid,test_size=0.2,random_state=42)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape,X_valid.shape,y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#loads the bert layer as tensorflow keras layer.\n",
    "transformer_layer = transformers.TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 23\n",
    "inp = Input(shape=(23, ))\n",
    "embedding_matrix=transformer_layer.weights[0].numpy()\n",
    "x = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],embeddings_initializer=Constant(embedding_matrix),trainable=False)(inp)\n",
    "x = Bidirectional(LSTM(25, return_sequences=True,recurrent_regularizer='L1L2'))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.9)(x)\n",
    "x = Dense(50, activation='relu',kernel_initializer='he_normal',kernel_regularizer=\"L1L2\")(x)\n",
    "x = Dropout(0.9)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[inp], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 23, 768)           23440896  \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 23, 50)           158800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 50)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 50)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 50)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,602,297\n",
      "Trainable params: 161,401\n",
      "Non-trainable params: 23,440,896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function creates a TensorBoard callback to be used during training to save log files for visualization.\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/bert_model/20230429-133440\n",
      "Epoch 1/5\n",
      "19924/19924 [==============================] - 575s 29ms/step - loss: 0.2426 - accuracy: 0.9311 - val_loss: 0.2023 - val_accuracy: 0.9317\n",
      "Epoch 2/5\n",
      "19924/19924 [==============================] - 697s 35ms/step - loss: 0.2093 - accuracy: 0.9328 - val_loss: 0.1804 - val_accuracy: 0.9329\n",
      "Epoch 3/5\n",
      "19924/19924 [==============================] - 696s 35ms/step - loss: 0.1958 - accuracy: 0.9358 - val_loss: 0.1695 - val_accuracy: 0.9410\n",
      "Epoch 4/5\n",
      "19924/19924 [==============================] - 714s 36ms/step - loss: 0.1882 - accuracy: 0.9384 - val_loss: 0.1585 - val_accuracy: 0.9442\n",
      "Epoch 5/5\n",
      "19924/19924 [==============================] - 720s 36ms/step - loss: 0.1837 - accuracy: 0.9399 - val_loss: 0.1556 - val_accuracy: 0.9472\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,batch_size=32,epochs=5,validation_data=(X_valid,y_valid),callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, experiment_name=\"bert_model\")]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4981/4981 [==============================] - 87s 18ms/step - loss: 0.1556 - accuracy: 0.9472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1555517017841339, 0.9471914172172546]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 53s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 94.77916182000926,\n",
       " 'precision': 0.943976298407921,\n",
       " 'recall': 0.9477916182000926,\n",
       " 'f1': 0.9351242416696955}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def calculate_results(y_true, y_pred): \n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results\n",
    "\n",
    "calculate_results(y_test,tf.squeeze(tf.round(model_preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
